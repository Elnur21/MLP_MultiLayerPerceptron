{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 10:27:03.472010: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-13 10:27:03.472139: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-13 10:27:03.529432: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-13 10:27:03.710264: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-13 10:27:04.761926: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "from models.FCN import FCN\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "from utils.helper import *\n",
    "from utils.constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 251, 1)]          0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 251, 128)          1152      \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 251, 128)          512       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " activation (Activation)     (None, 251, 128)          0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 251, 256)          164096    \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 251, 256)          1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 251, 256)          0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 251, 128)          98432     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 251, 128)          512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 251, 128)          0         \n",
      "                                                                 \n",
      " global_average_pooling1d (  (None, 128)               0         \n",
      " GlobalAveragePooling1D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266115 (1.02 MB)\n",
      "Trainable params: 265091 (1.01 MB)\n",
      "Non-trainable params: 1024 (4.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 10:27:11.639265: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-13 10:27:11.874189: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-13 10:27:11.874393: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-13 10:27:11.875444: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-13 10:27:11.875611: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-13 10:27:11.875755: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-13 10:27:11.958536: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-13 10:27:11.958704: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-13 10:27:11.958836: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-13 10:27:11.958936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 176 MB memory:  -> device: 0, name: Quadro P400, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "2024-03-13 10:27:11.975898: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1101] failed to allocate 176.06MiB (184614912 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    }
   ],
   "source": [
    "df = read_dataset(\"ArrowHead\")\n",
    "\n",
    "X_train = df[0].reshape(df[0].shape[0], df[0].shape[1], 1)\n",
    "X_test = df[2].reshape(df[2].shape[0], df[2].shape[1], 1)\n",
    "# apply one-hot encoder\n",
    "y_train=to_categorical(df[1])\n",
    "y_test=to_categorical(df[3])\n",
    "\n",
    "model = FCN(input_size=X_train.shape[1:] , nb_classes=y_train.shape[1], filters=[128,256,128])\n",
    "model.compile(optimizer=Adam(learning_rate=0.01), loss=CategoricalCrossentropy(), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test (36, 251, 1)\n",
      "Epoch 1/1000\n",
      "An error occurred: in user code:\n",
      "\n",
      "    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n",
      "        return step_function(self, iterator)\n",
      "    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n",
      "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n",
      "        outputs = model.train_step(data)\n",
      "    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1151, in train_step\n",
      "        loss = self.compute_loss(x, y, y_pred, sample_weight)\n",
      "    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n",
      "        return self.compiled_loss(\n",
      "    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.10/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n",
      "        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n",
      "    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.10/site-packages/keras/src/losses.py\", line 143, in __call__\n",
      "        losses = call_fn(y_true, y_pred)\n",
      "    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.10/site-packages/keras/src/losses.py\", line 270, in call  **\n",
      "        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n",
      "    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.10/site-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n",
      "        return backend.categorical_crossentropy(\n",
      "    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.10/site-packages/keras/src/backend.py\", line 5573, in categorical_crossentropy\n",
      "        target.shape.assert_is_compatible_with(output.shape)\n",
      "\n",
      "    ValueError: Shapes (None, 3) and (None, 128) are incompatible\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results=[]\n",
    "histories=[]\n",
    "\n",
    "try:\n",
    "    for dataset in  UNIVARIATE_DATASET_NAMES_2018:\n",
    "        with tf.device(\"/device:GPU:0\"):\n",
    "            # Load data\n",
    "            df = read_dataset(dataset)\n",
    "\n",
    "            X_train = df[0].reshape(df[0].shape[0], df[0].shape[1], 1)\n",
    "            X_test = df[2].reshape(df[2].shape[0], df[2].shape[1], 1)\n",
    "\n",
    "            # apply one-hot encoder\n",
    "            y_train=to_categorical(df[1])\n",
    "            y_test=to_categorical(df[3])\n",
    "            print(\"test\",X_train.shape)\n",
    "\n",
    "            # Compile the model\n",
    "            model = FCN(input_size=X_train.shape[1:] , nb_classes=y_train.shape[1], filters=[128,256,128])\n",
    "            model.compile(optimizer=Adam(learning_rate=0.01), loss=CategoricalCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "            callbacks =[\n",
    "                tf.keras.callbacks.ModelCheckpoint(\n",
    "                    f\"best_models/best_model_distiller_{dataset}.tf\", save_weights_only=True, monitor=\"lr\"\n",
    "                ),\n",
    "                tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                    monitor=\"lr\", factor=0.5, patience=50, min_lr=0.0001\n",
    "                ),\n",
    "            ]\n",
    "\n",
    "            # Train the model\n",
    "            history = model.fit(X_train, y_train, batch_size=16, epochs=1000, validation_data= (df[2], y_test), callbacks = callbacks)\n",
    "\n",
    "            # Evaluate the model\n",
    "            train_loss, train_accuracy = model.evaluate(X_train, y_train)\n",
    "            test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "            results.append([dataset, train_loss, train_accuracy, test_loss, test_accuracy])\n",
    "            histories.append(history.history)\n",
    "        # clear_gpu_memory()\n",
    "            \n",
    "    pd.DataFrame(results, columns=[\"Dataset\",\"Train loss\", \"Train accuracy\",\"Test loss\", \"Test accuracy\"]).to_csv(\"result.csv\", index=False)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)\n",
    "\n",
    "\n",
    "for i in range(len(histories)):\n",
    "    plot_loss(histories[i], UNIVARIATE_DATASET_NAMES_2018[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Train loss</th>\n",
       "      <th>Train accuracy</th>\n",
       "      <th>Test loss</th>\n",
       "      <th>Test accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ArrowHead</td>\n",
       "      <td>2.169613e-02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.588603</td>\n",
       "      <td>0.811429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wine</td>\n",
       "      <td>5.724999e-01</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.568843</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OliveOil</td>\n",
       "      <td>1.008327e+00</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.068600</td>\n",
       "      <td>0.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Car</td>\n",
       "      <td>9.128553e-03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.179467</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BeetleFly</td>\n",
       "      <td>1.187496e-02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.521813</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Yoga</td>\n",
       "      <td>1.083056e-01</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.460021</td>\n",
       "      <td>0.812667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>InlineSkate</td>\n",
       "      <td>1.254727e+00</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>1.976222</td>\n",
       "      <td>0.283636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FaceAll</td>\n",
       "      <td>3.761476e-07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.845623</td>\n",
       "      <td>0.850296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ham</td>\n",
       "      <td>6.499323e-03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.159491</td>\n",
       "      <td>0.752381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MoteStrain</td>\n",
       "      <td>1.450405e-03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.249668</td>\n",
       "      <td>0.924121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ProximalPhalanxTW</td>\n",
       "      <td>4.603189e-02</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.715811</td>\n",
       "      <td>0.795122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>WordSynonyms</td>\n",
       "      <td>1.080845e-02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.148380</td>\n",
       "      <td>0.496865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Lightning7</td>\n",
       "      <td>5.255145e-03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.655851</td>\n",
       "      <td>0.780822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GunPointOldVersusYoung</td>\n",
       "      <td>3.935196e-03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.110991</td>\n",
       "      <td>0.974603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Earthquakes</td>\n",
       "      <td>3.930673e-03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.249711</td>\n",
       "      <td>0.712230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Dataset    Train loss  Train accuracy  Test loss  \\\n",
       "0                ArrowHead  2.169613e-02        1.000000   0.588603   \n",
       "1                     Wine  5.724999e-01        0.701754   0.568843   \n",
       "2                 OliveOil  1.008327e+00        0.500000   1.068600   \n",
       "3                      Car  9.128553e-03        1.000000   0.179467   \n",
       "4                BeetleFly  1.187496e-02        1.000000   0.521813   \n",
       "5                     Yoga  1.083056e-01        0.980000   0.460021   \n",
       "6              InlineSkate  1.254727e+00        0.510000   1.976222   \n",
       "7                  FaceAll  3.761476e-07        1.000000   0.845623   \n",
       "8                      Ham  6.499323e-03        1.000000   1.159491   \n",
       "9               MoteStrain  1.450405e-03        1.000000   0.249668   \n",
       "10       ProximalPhalanxTW  4.603189e-02        0.985000   0.715811   \n",
       "11            WordSynonyms  1.080845e-02        1.000000   3.148380   \n",
       "12              Lightning7  5.255145e-03        1.000000   0.655851   \n",
       "13  GunPointOldVersusYoung  3.935196e-03        1.000000   0.110991   \n",
       "14             Earthquakes  3.930673e-03        1.000000   1.249711   \n",
       "\n",
       "    Test accuracy  \n",
       "0        0.811429  \n",
       "1        0.722222  \n",
       "2        0.433333  \n",
       "3        0.916667  \n",
       "4        0.750000  \n",
       "5        0.812667  \n",
       "6        0.283636  \n",
       "7        0.850296  \n",
       "8        0.752381  \n",
       "9        0.924121  \n",
       "10       0.795122  \n",
       "11       0.496865  \n",
       "12       0.780822  \n",
       "13       0.974603  \n",
       "14       0.712230  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.read_csv(\"result.csv\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Train loss</th>\n",
       "      <th>Train accuracy</th>\n",
       "      <th>Test loss</th>\n",
       "      <th>Test accuracy</th>\n",
       "      <th>FCN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ArrowHead</td>\n",
       "      <td>2.169613e-02</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.588603</td>\n",
       "      <td>81.14</td>\n",
       "      <td>84.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wine</td>\n",
       "      <td>5.724999e-01</td>\n",
       "      <td>70.18</td>\n",
       "      <td>0.568843</td>\n",
       "      <td>72.22</td>\n",
       "      <td>58.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OliveOil</td>\n",
       "      <td>1.008327e+00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>1.068600</td>\n",
       "      <td>43.33</td>\n",
       "      <td>72.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Car</td>\n",
       "      <td>9.128553e-03</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.179467</td>\n",
       "      <td>91.67</td>\n",
       "      <td>90.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BeetleFly</td>\n",
       "      <td>1.187496e-02</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.521813</td>\n",
       "      <td>75.00</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Yoga</td>\n",
       "      <td>1.083056e-01</td>\n",
       "      <td>98.00</td>\n",
       "      <td>0.460021</td>\n",
       "      <td>81.27</td>\n",
       "      <td>83.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>InlineSkate</td>\n",
       "      <td>1.254727e+00</td>\n",
       "      <td>51.00</td>\n",
       "      <td>1.976222</td>\n",
       "      <td>28.36</td>\n",
       "      <td>33.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FaceAll</td>\n",
       "      <td>3.761476e-07</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.845623</td>\n",
       "      <td>85.03</td>\n",
       "      <td>94.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ham</td>\n",
       "      <td>6.499323e-03</td>\n",
       "      <td>100.00</td>\n",
       "      <td>1.159491</td>\n",
       "      <td>75.24</td>\n",
       "      <td>71.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MoteStrain</td>\n",
       "      <td>1.450405e-03</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.249668</td>\n",
       "      <td>92.41</td>\n",
       "      <td>93.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ProximalPhalanxTW</td>\n",
       "      <td>4.603189e-02</td>\n",
       "      <td>98.50</td>\n",
       "      <td>0.715811</td>\n",
       "      <td>79.51</td>\n",
       "      <td>76.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>WordSynonyms</td>\n",
       "      <td>1.080845e-02</td>\n",
       "      <td>100.00</td>\n",
       "      <td>3.148380</td>\n",
       "      <td>49.69</td>\n",
       "      <td>56.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Lightning7</td>\n",
       "      <td>5.255145e-03</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.655851</td>\n",
       "      <td>78.08</td>\n",
       "      <td>82.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GunPointOldVersusYoung</td>\n",
       "      <td>3.935196e-03</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.110991</td>\n",
       "      <td>97.46</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Earthquakes</td>\n",
       "      <td>3.930673e-03</td>\n",
       "      <td>100.00</td>\n",
       "      <td>1.249711</td>\n",
       "      <td>71.22</td>\n",
       "      <td>72.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Dataset    Train loss  Train accuracy  Test loss  \\\n",
       "0                ArrowHead  2.169613e-02          100.00   0.588603   \n",
       "1                     Wine  5.724999e-01           70.18   0.568843   \n",
       "2                 OliveOil  1.008327e+00           50.00   1.068600   \n",
       "3                      Car  9.128553e-03          100.00   0.179467   \n",
       "4                BeetleFly  1.187496e-02          100.00   0.521813   \n",
       "5                     Yoga  1.083056e-01           98.00   0.460021   \n",
       "6              InlineSkate  1.254727e+00           51.00   1.976222   \n",
       "7                  FaceAll  3.761476e-07          100.00   0.845623   \n",
       "8                      Ham  6.499323e-03          100.00   1.159491   \n",
       "9               MoteStrain  1.450405e-03          100.00   0.249668   \n",
       "10       ProximalPhalanxTW  4.603189e-02           98.50   0.715811   \n",
       "11            WordSynonyms  1.080845e-02          100.00   3.148380   \n",
       "12              Lightning7  5.255145e-03          100.00   0.655851   \n",
       "13  GunPointOldVersusYoung  3.935196e-03          100.00   0.110991   \n",
       "14             Earthquakes  3.930673e-03          100.00   1.249711   \n",
       "\n",
       "    Test accuracy    FCN  \n",
       "0           81.14   84.3  \n",
       "1           72.22   58.7  \n",
       "2           43.33   72.3  \n",
       "3           91.67   90.5  \n",
       "4           75.00   86.0  \n",
       "5           81.27   83.9  \n",
       "6           28.36   33.9  \n",
       "7           85.03   94.5  \n",
       "8           75.24   71.8  \n",
       "9           92.41   93.7  \n",
       "10          79.51   76.7  \n",
       "11          49.69   56.4  \n",
       "12          78.08   82.7  \n",
       "13          97.46  100.0  \n",
       "14          71.22   72.7  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"results-uea-avg-std.csv\")\n",
    "\n",
    "# remove std\n",
    "def remove_parenthesis(value):\n",
    "    return float(value.split(\"(\")[0])\n",
    "\n",
    "def convert_to_percent(value):\n",
    "    return float(\"%.2f\" % float(value*100))\n",
    "\n",
    "df.iloc[:, 1:] = df.iloc[:, 1:].map(remove_parenthesis)\n",
    "results[\"Train accuracy\"]=results[\"Train accuracy\"].apply(convert_to_percent)\n",
    "results[\"Test accuracy\"]=results[\"Test accuracy\"].apply(convert_to_percent)\n",
    "\n",
    "df['Unnamed: 0'] = df['Unnamed: 0'].str.lower()\n",
    "dataset_names = pd.Series(UNIVARIATE_DATASET_NAMES_2018, name=\"Unnamed: 0\").str.lower()\n",
    "df_copy = df.merge(dataset_names, on='Unnamed: 0', how='right')\n",
    "df_copy.dropna(axis=0, inplace=True)\n",
    "\n",
    "results['Unnamed: 0'] = results['Dataset'].str.lower()\n",
    "\n",
    "# merge and remove unused columns\n",
    "result = results.merge(df_copy[[\"Unnamed: 0\",\"FCN\"]],on=\"Unnamed: 0\",how=\"right\").drop(\"Unnamed: 0\",axis=1)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_1v1_perf(result,\"FCN\",\"Test accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16c1a6cef089e7df03eb3ef6b302c9876f8716d8e0fa74aeb62504d533a43d66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
