{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "3/3 [==============================] - 1s 83ms/step - loss: 5.1172 - accuracy: 0.3889 - val_loss: 12.1676 - val_accuracy: 0.3029\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 8.1285 - accuracy: 0.4722 - val_loss: 17.2036 - val_accuracy: 0.3029\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 11.0052 - accuracy: 0.3889 - val_loss: 3.0136 - val_accuracy: 0.5657\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 4.3137 - accuracy: 0.5000 - val_loss: 2.2303 - val_accuracy: 0.5429\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 2.0352 - accuracy: 0.5833 - val_loss: 1.0155 - val_accuracy: 0.5657\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 1.1171 - accuracy: 0.5556 - val_loss: 1.1619 - val_accuracy: 0.5371\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.8972 - accuracy: 0.5556 - val_loss: 1.0019 - val_accuracy: 0.5771\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 1.1564 - accuracy: 0.5278 - val_loss: 1.0111 - val_accuracy: 0.5771\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5884 - accuracy: 0.6667 - val_loss: 0.9781 - val_accuracy: 0.5429\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.7782 - accuracy: 0.5556 - val_loss: 0.8561 - val_accuracy: 0.6571\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.7425 - accuracy: 0.5833 - val_loss: 0.8602 - val_accuracy: 0.7143\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.7889 - accuracy: 0.5000 - val_loss: 0.9190 - val_accuracy: 0.6971\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.7343 - accuracy: 0.5556 - val_loss: 1.0037 - val_accuracy: 0.6457\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.7844 - accuracy: 0.6389 - val_loss: 1.0294 - val_accuracy: 0.6171\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6831 - accuracy: 0.6111 - val_loss: 1.1099 - val_accuracy: 0.6057\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.6560 - accuracy: 0.6944 - val_loss: 1.2121 - val_accuracy: 0.6000\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7279 - accuracy: 0.6111 - val_loss: 1.2863 - val_accuracy: 0.5771\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.7189 - accuracy: 0.6389 - val_loss: 1.3676 - val_accuracy: 0.5429\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6309 - accuracy: 0.6667 - val_loss: 1.3734 - val_accuracy: 0.5657\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.8371 - accuracy: 0.6111 - val_loss: 1.3840 - val_accuracy: 0.6514\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.7383 - accuracy: 0.5833 - val_loss: 1.3138 - val_accuracy: 0.5657\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.7562 - accuracy: 0.5833 - val_loss: 1.3084 - val_accuracy: 0.6400\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6621 - accuracy: 0.6389 - val_loss: 1.3426 - val_accuracy: 0.5257\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6311 - accuracy: 0.6944 - val_loss: 1.3066 - val_accuracy: 0.4971\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6902 - accuracy: 0.5278 - val_loss: 1.2987 - val_accuracy: 0.5314\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.8514 - accuracy: 0.5833 - val_loss: 1.3633 - val_accuracy: 0.4743\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.7291 - accuracy: 0.4722 - val_loss: 1.3393 - val_accuracy: 0.4914\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.7394 - accuracy: 0.6389 - val_loss: 1.2643 - val_accuracy: 0.5600\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.7560 - accuracy: 0.5556 - val_loss: 1.2373 - val_accuracy: 0.5657\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.9778 - accuracy: 0.6389 - val_loss: 1.1987 - val_accuracy: 0.5429\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.7496 - accuracy: 0.5556 - val_loss: 1.1819 - val_accuracy: 0.5371\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6075 - accuracy: 0.6667 - val_loss: 1.1667 - val_accuracy: 0.4743\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7661 - accuracy: 0.6389 - val_loss: 1.1312 - val_accuracy: 0.5029\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6710 - accuracy: 0.6667 - val_loss: 1.1134 - val_accuracy: 0.4857\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7577 - accuracy: 0.5556 - val_loss: 1.1135 - val_accuracy: 0.5029\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5805 - accuracy: 0.6667 - val_loss: 1.1232 - val_accuracy: 0.5257\n",
      "Epoch 37/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6035 - accuracy: 0.6944 - val_loss: 1.1654 - val_accuracy: 0.5314\n",
      "Epoch 38/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.7722 - accuracy: 0.6389 - val_loss: 1.1551 - val_accuracy: 0.5143\n",
      "Epoch 39/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5927 - accuracy: 0.6111 - val_loss: 1.1487 - val_accuracy: 0.4914\n",
      "Epoch 40/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6186 - accuracy: 0.7222 - val_loss: 1.1423 - val_accuracy: 0.4971\n",
      "Epoch 41/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6564 - accuracy: 0.5556 - val_loss: 1.1271 - val_accuracy: 0.5143\n",
      "Epoch 42/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6018 - accuracy: 0.6111 - val_loss: 1.1040 - val_accuracy: 0.5314\n",
      "Epoch 43/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6248 - accuracy: 0.6389 - val_loss: 1.0531 - val_accuracy: 0.5486\n",
      "Epoch 44/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.9771 - accuracy: 0.5833 - val_loss: 1.1836 - val_accuracy: 0.5314\n",
      "Epoch 45/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5824 - accuracy: 0.6667 - val_loss: 1.2785 - val_accuracy: 0.5429\n",
      "Epoch 46/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5262 - accuracy: 0.7222 - val_loss: 1.3563 - val_accuracy: 0.5371\n",
      "Epoch 47/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6072 - accuracy: 0.6667 - val_loss: 1.4138 - val_accuracy: 0.4857\n",
      "Epoch 48/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6123 - accuracy: 0.6944 - val_loss: 1.3755 - val_accuracy: 0.4743\n",
      "Epoch 49/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6717 - accuracy: 0.6667 - val_loss: 1.3524 - val_accuracy: 0.4686\n",
      "Epoch 50/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.8029 - accuracy: 0.6111 - val_loss: 1.5045 - val_accuracy: 0.5029\n",
      "Epoch 51/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6160 - accuracy: 0.6667 - val_loss: 1.6020 - val_accuracy: 0.5714\n",
      "Epoch 52/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5576 - accuracy: 0.7500 - val_loss: 1.6997 - val_accuracy: 0.6800\n",
      "Epoch 53/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.7414 - accuracy: 0.6667 - val_loss: 1.8501 - val_accuracy: 0.5314\n",
      "Epoch 54/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.7320 - accuracy: 0.6111 - val_loss: 1.8116 - val_accuracy: 0.5429\n",
      "Epoch 55/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7103 - accuracy: 0.6389 - val_loss: 1.7965 - val_accuracy: 0.5086\n",
      "Epoch 56/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6801 - accuracy: 0.5556 - val_loss: 1.7928 - val_accuracy: 0.4971\n",
      "Epoch 57/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6920 - accuracy: 0.6111 - val_loss: 1.7891 - val_accuracy: 0.4800\n",
      "Epoch 58/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6334 - accuracy: 0.6389 - val_loss: 1.9144 - val_accuracy: 0.5886\n",
      "Epoch 59/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.8518 - accuracy: 0.5556 - val_loss: 1.8238 - val_accuracy: 0.4629\n",
      "Epoch 60/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6841 - accuracy: 0.6389 - val_loss: 1.8047 - val_accuracy: 0.4629\n",
      "Epoch 61/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6787 - accuracy: 0.6111 - val_loss: 1.7827 - val_accuracy: 0.4629\n",
      "Epoch 62/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.7635 - accuracy: 0.5278 - val_loss: 1.6820 - val_accuracy: 0.5143\n",
      "Epoch 63/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.7492 - accuracy: 0.5833 - val_loss: 1.7077 - val_accuracy: 0.5143\n",
      "Epoch 64/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7501 - accuracy: 0.5556 - val_loss: 1.7097 - val_accuracy: 0.4800\n",
      "Epoch 65/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6864 - accuracy: 0.6944 - val_loss: 2.5509 - val_accuracy: 0.4914\n",
      "Epoch 66/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.1761 - accuracy: 0.4444 - val_loss: 1.6550 - val_accuracy: 0.4857\n",
      "Epoch 67/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.7970 - accuracy: 0.5833 - val_loss: 1.8056 - val_accuracy: 0.4400\n",
      "Epoch 68/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.7959 - accuracy: 0.5833 - val_loss: 1.7975 - val_accuracy: 0.4229\n",
      "Epoch 69/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.8148 - accuracy: 0.5278 - val_loss: 1.7261 - val_accuracy: 0.4457\n",
      "Epoch 70/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.8694 - accuracy: 0.5556 - val_loss: 1.6006 - val_accuracy: 0.5257\n",
      "Epoch 71/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.7828 - accuracy: 0.5556 - val_loss: 1.5606 - val_accuracy: 0.5600\n",
      "Epoch 72/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.8646 - accuracy: 0.5556 - val_loss: 1.5926 - val_accuracy: 0.5543\n",
      "Epoch 73/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.9147 - accuracy: 0.5556 - val_loss: 1.6055 - val_accuracy: 0.5371\n",
      "Epoch 74/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.8205 - accuracy: 0.4722 - val_loss: 1.6581 - val_accuracy: 0.5829\n",
      "Epoch 75/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 1.1240 - accuracy: 0.4722 - val_loss: 1.4908 - val_accuracy: 0.5829\n",
      "Epoch 76/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.7400 - accuracy: 0.6667 - val_loss: 1.4503 - val_accuracy: 0.5143\n",
      "Epoch 77/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5992 - accuracy: 0.7222 - val_loss: 1.4537 - val_accuracy: 0.5200\n",
      "Epoch 78/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 1.0202 - accuracy: 0.6389 - val_loss: 1.4633 - val_accuracy: 0.4971\n",
      "Epoch 79/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.7307 - accuracy: 0.6667 - val_loss: 1.4651 - val_accuracy: 0.4743\n",
      "Epoch 80/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6311 - accuracy: 0.6111 - val_loss: 1.4791 - val_accuracy: 0.5029\n",
      "Epoch 81/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6870 - accuracy: 0.6667 - val_loss: 1.5289 - val_accuracy: 0.5200\n",
      "Epoch 82/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.8862 - accuracy: 0.4444 - val_loss: 1.5394 - val_accuracy: 0.5029\n",
      "Epoch 83/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7386 - accuracy: 0.6389 - val_loss: 1.5531 - val_accuracy: 0.4971\n",
      "Epoch 84/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.7220 - accuracy: 0.5833 - val_loss: 1.5728 - val_accuracy: 0.4971\n",
      "Epoch 85/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6956 - accuracy: 0.6667 - val_loss: 1.5935 - val_accuracy: 0.5086\n",
      "Epoch 86/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.7334 - accuracy: 0.6111 - val_loss: 1.6252 - val_accuracy: 0.4971\n",
      "Epoch 87/1000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.7026 - accuracy: 0.6111 - val_loss: 1.5984 - val_accuracy: 0.5029\n",
      "Epoch 88/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.7298 - accuracy: 0.5833 - val_loss: 1.6027 - val_accuracy: 0.4971\n",
      "Epoch 89/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.7280 - accuracy: 0.6667 - val_loss: 1.6256 - val_accuracy: 0.5086\n",
      "Epoch 90/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6662 - accuracy: 0.5556 - val_loss: 1.6659 - val_accuracy: 0.5029\n",
      "Epoch 91/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7168 - accuracy: 0.5556 - val_loss: 1.6990 - val_accuracy: 0.5086\n",
      "Epoch 92/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.8627 - accuracy: 0.5556 - val_loss: 1.7144 - val_accuracy: 0.5086\n",
      "Epoch 93/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6874 - accuracy: 0.6111 - val_loss: 1.7319 - val_accuracy: 0.5086\n",
      "Epoch 94/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6842 - accuracy: 0.6667 - val_loss: 1.7375 - val_accuracy: 0.5371\n",
      "Epoch 95/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7371 - accuracy: 0.6875"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m), loss\u001b[38;5;241m=\u001b[39mCategoricalCrossentropy(), metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m     35\u001b[0m train_loss, train_accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(df[\u001b[38;5;241m0\u001b[39m], y_train)\n",
      "File \u001b[0;32m~/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.10/site-packages/keras/src/engine/training.py:1856\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1840\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1841\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[1;32m   1842\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[1;32m   1843\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1854\u001b[0m         pss_evaluation_shards\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pss_evaluation_shards,\n\u001b[1;32m   1855\u001b[0m     )\n\u001b[0;32m-> 1856\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1858\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1859\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1860\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1864\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1866\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1867\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1868\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1869\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1870\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   1871\u001b[0m }\n\u001b[1;32m   1872\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m~/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.10/site-packages/keras/src/engine/training.py:2295\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2291\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[1;32m   2292\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   2293\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2294\u001b[0m             ):\n\u001b[0;32m-> 2295\u001b[0m                 \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_test_batch_begin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2296\u001b[0m                 logs \u001b[38;5;241m=\u001b[39m test_function_runner\u001b[38;5;241m.\u001b[39mrun_step(\n\u001b[1;32m   2297\u001b[0m                     dataset_or_iterator,\n\u001b[1;32m   2298\u001b[0m                     data_handler,\n\u001b[1;32m   2299\u001b[0m                     step,\n\u001b[1;32m   2300\u001b[0m                     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pss_evaluation_shards,\n\u001b[1;32m   2301\u001b[0m                 )\n\u001b[1;32m   2303\u001b[0m logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n",
      "File \u001b[0;32m~/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.10/site-packages/keras/src/callbacks.py:487\u001b[0m, in \u001b[0;36mCallbackList.on_test_batch_begin\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the `on_test_batch_begin` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    479\u001b[0m \n\u001b[1;32m    480\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;124;03m      Example: `{'loss': 0.2, 'accuracy': 0.7}`.\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_test_batch_hooks:\n\u001b[0;32m--> 487\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTEST\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbegin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.10/site-packages/keras/src/callbacks.py:320\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 320\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_begin_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_end_hook(mode, batch, logs)\n",
      "File \u001b[0;32m~/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.10/site-packages/keras/src/callbacks.py:334\u001b[0m, in \u001b[0;36mCallbackList._call_batch_begin_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    331\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_batch_begin\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[0;32m--> 334\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "from utils.helper import *\n",
    "from utils.constants import *\n",
    "from models.MLP import MultiLayerPerceptron\n",
    "\n",
    "\n",
    "\n",
    "results=[]\n",
    "histories=[]\n",
    "\n",
    "try:\n",
    "    for dataset in  UNIVARIATE_DATASET_NAMES_2018:\n",
    "        with tf.device(\"/device:GPU:0\"):\n",
    "            # Load data\n",
    "            df = read_dataset(dataset)\n",
    "\n",
    "            # apply one-hot encoder\n",
    "            y_train=to_categorical(df[1])\n",
    "            y_test=to_categorical(df[3])\n",
    "\n",
    "            # Compile the model\n",
    "            model = MultiLayerPerceptron(input_size=df[0].shape[1], num_labels=y_train.shape[1])\n",
    "            model.compile(optimizer=Adam(learning_rate=0.01), loss=CategoricalCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "            # Train the model\n",
    "            history = model.fit(df[0], y_train, batch_size=16, epochs=1000, validation_data= (df[2], y_test))\n",
    "\n",
    "            # Evaluate the model\n",
    "            train_loss, train_accuracy = model.evaluate(df[0], y_train)\n",
    "            test_loss, test_accuracy = model.evaluate(df[2], y_test)\n",
    "\n",
    "            results.append([dataset, train_loss, train_accuracy, test_loss, test_accuracy])\n",
    "            histories.append(history.history)\n",
    "        # clear_gpu_memory()\n",
    "            \n",
    "    pd.DataFrame(results, columns=[\"Dataset\",\"Train loss\", \"Train accuracy\",\"Test loss\", \"Test accuracy\"]).to_csv(\"result.csv\", index=False)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)\n",
    "\n",
    "\n",
    "for i in range(len(histories)):\n",
    "    plot_loss(histories[i], UNIVARIATE_DATASET_NAMES_2018[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Train loss</th>\n",
       "      <th>Train accuracy</th>\n",
       "      <th>Test loss</th>\n",
       "      <th>Test accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ArrowHead</td>\n",
       "      <td>0.678126</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>3.620084</td>\n",
       "      <td>0.485714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wine</td>\n",
       "      <td>0.691872</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.695424</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OliveOil</td>\n",
       "      <td>1.282252</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>1.299150</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Car</td>\n",
       "      <td>1.151810</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>5.328006</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BeetleFly</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>46007.804688</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Yoga</td>\n",
       "      <td>0.689401</td>\n",
       "      <td>0.543333</td>\n",
       "      <td>0.690652</td>\n",
       "      <td>0.535667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>InlineSkate</td>\n",
       "      <td>1.921015</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>1.924656</td>\n",
       "      <td>0.154545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FaceAll</td>\n",
       "      <td>2.639132</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>2.639947</td>\n",
       "      <td>0.039053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ham</td>\n",
       "      <td>0.685378</td>\n",
       "      <td>0.532110</td>\n",
       "      <td>0.693511</td>\n",
       "      <td>0.514286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MoteStrain</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1332.437378</td>\n",
       "      <td>0.859425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ProximalPhalanxTW</td>\n",
       "      <td>1.406431</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>1.474520</td>\n",
       "      <td>0.351220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>WordSynonyms</td>\n",
       "      <td>2.789938</td>\n",
       "      <td>0.224719</td>\n",
       "      <td>2.875024</td>\n",
       "      <td>0.219436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Lightning7</td>\n",
       "      <td>1.281135</td>\n",
       "      <td>0.528571</td>\n",
       "      <td>2662.084229</td>\n",
       "      <td>0.356164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GunPointOldVersusYoung</td>\n",
       "      <td>0.591154</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.563984</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Earthquakes</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>88013.867188</td>\n",
       "      <td>0.669065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Dataset  Train loss  Train accuracy     Test loss  \\\n",
       "0                ArrowHead    0.678126        0.638889      3.620084   \n",
       "1                     Wine    0.691872        0.526316      0.695424   \n",
       "2                 OliveOil    1.282252        0.433333      1.299150   \n",
       "3                      Car    1.151810        0.400000      5.328006   \n",
       "4                BeetleFly    0.000000        1.000000  46007.804688   \n",
       "5                     Yoga    0.689401        0.543333      0.690652   \n",
       "6              InlineSkate    1.921015        0.180000      1.924656   \n",
       "7                  FaceAll    2.639132        0.071429      2.639947   \n",
       "8                      Ham    0.685378        0.532110      0.693511   \n",
       "9               MoteStrain    0.000000        1.000000   1332.437378   \n",
       "10       ProximalPhalanxTW    1.406431        0.450000      1.474520   \n",
       "11            WordSynonyms    2.789938        0.224719      2.875024   \n",
       "12              Lightning7    1.281135        0.528571   2662.084229   \n",
       "13  GunPointOldVersusYoung    0.591154        0.617647      0.563984   \n",
       "14             Earthquakes    0.000000        1.000000  88013.867188   \n",
       "\n",
       "    Test accuracy  \n",
       "0        0.485714  \n",
       "1        0.500000  \n",
       "2        0.400000  \n",
       "3        0.333333  \n",
       "4        0.850000  \n",
       "5        0.535667  \n",
       "6        0.154545  \n",
       "7        0.039053  \n",
       "8        0.514286  \n",
       "9        0.859425  \n",
       "10       0.351220  \n",
       "11       0.219436  \n",
       "12       0.356164  \n",
       "13       0.650794  \n",
       "14       0.669065  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.read_csv(\"result.csv\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Train loss</th>\n",
       "      <th>Train accuracy</th>\n",
       "      <th>Test loss</th>\n",
       "      <th>Test accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ArrowHead</td>\n",
       "      <td>0.003899</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.387911</td>\n",
       "      <td>0.685714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wine</td>\n",
       "      <td>0.691779</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.694387</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OliveOil</td>\n",
       "      <td>1.282821</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>1.296988</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Car</td>\n",
       "      <td>0.352149</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.172970</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BeetleFly</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1421.919678</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Yoga</td>\n",
       "      <td>0.689453</td>\n",
       "      <td>0.543333</td>\n",
       "      <td>0.690578</td>\n",
       "      <td>0.535667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>InlineSkate</td>\n",
       "      <td>1.920965</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>4.587185</td>\n",
       "      <td>0.150909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FaceAll</td>\n",
       "      <td>2.629645</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>2.915818</td>\n",
       "      <td>0.082249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ham</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.105940</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MoteStrain</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.603525</td>\n",
       "      <td>0.861022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ProximalPhalanxTW</td>\n",
       "      <td>0.392543</td>\n",
       "      <td>0.827500</td>\n",
       "      <td>0.533478</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>WordSynonyms</td>\n",
       "      <td>2.789930</td>\n",
       "      <td>0.224719</td>\n",
       "      <td>2.874707</td>\n",
       "      <td>0.219436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Lightning7</td>\n",
       "      <td>0.001244</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>929.380554</td>\n",
       "      <td>0.534247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GunPointOldVersusYoung</td>\n",
       "      <td>0.602803</td>\n",
       "      <td>0.602941</td>\n",
       "      <td>51.340347</td>\n",
       "      <td>0.596825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Earthquakes</td>\n",
       "      <td>0.027670</td>\n",
       "      <td>0.990683</td>\n",
       "      <td>3220.412109</td>\n",
       "      <td>0.661870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Dataset  Train loss  Train accuracy    Test loss  \\\n",
       "0                ArrowHead    0.003899        1.000000     7.387911   \n",
       "1                     Wine    0.691779        0.526316     0.694387   \n",
       "2                 OliveOil    1.282821        0.433333     1.296988   \n",
       "3                      Car    0.352149        0.833333     1.172970   \n",
       "4                BeetleFly    0.000000        1.000000  1421.919678   \n",
       "5                     Yoga    0.689453        0.543333     0.690578   \n",
       "6              InlineSkate    1.920965        0.180000     4.587185   \n",
       "7                  FaceAll    2.629645        0.075000     2.915818   \n",
       "8                      Ham    0.000000        1.000000     8.105940   \n",
       "9               MoteStrain    0.000000        1.000000     2.603525   \n",
       "10       ProximalPhalanxTW    0.392543        0.827500     0.533478   \n",
       "11            WordSynonyms    2.789930        0.224719     2.874707   \n",
       "12              Lightning7    0.001244        1.000000   929.380554   \n",
       "13  GunPointOldVersusYoung    0.602803        0.602941    51.340347   \n",
       "14             Earthquakes    0.027670        0.990683  3220.412109   \n",
       "\n",
       "    Test accuracy  \n",
       "0        0.685714  \n",
       "1        0.500000  \n",
       "2        0.400000  \n",
       "3        0.616667  \n",
       "4        0.800000  \n",
       "5        0.535667  \n",
       "6        0.150909  \n",
       "7        0.082249  \n",
       "8        0.733333  \n",
       "9        0.861022  \n",
       "10       0.800000  \n",
       "11       0.219436  \n",
       "12       0.534247  \n",
       "13       0.596825  \n",
       "14       0.661870  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.read_csv(\"result.csv\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>MLP</th>\n",
       "      <th>FCN</th>\n",
       "      <th>ResNet</th>\n",
       "      <th>Encoder</th>\n",
       "      <th>MCNN</th>\n",
       "      <th>t-LeNet</th>\n",
       "      <th>MCDCNN</th>\n",
       "      <th>Time-CNN</th>\n",
       "      <th>TWIESN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50words</td>\n",
       "      <td>68.4(7.1)</td>\n",
       "      <td>62.7(6.1)</td>\n",
       "      <td>74.0(1.5)</td>\n",
       "      <td>72.3(1.0)</td>\n",
       "      <td>22.0(24.3)</td>\n",
       "      <td>12.5(0.0)</td>\n",
       "      <td>58.9(5.3)</td>\n",
       "      <td>62.1(1.0)</td>\n",
       "      <td>49.6(2.6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adiac</td>\n",
       "      <td>39.7(1.9)</td>\n",
       "      <td>84.4(0.7)</td>\n",
       "      <td>82.9(0.6)</td>\n",
       "      <td>48.4(2.5)</td>\n",
       "      <td>2.2(0.6)</td>\n",
       "      <td>2.0(0.0)</td>\n",
       "      <td>61.0(8.7)</td>\n",
       "      <td>37.9(2.0)</td>\n",
       "      <td>41.6(4.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ArrowHead</td>\n",
       "      <td>77.8(1.2)</td>\n",
       "      <td>84.3(1.5)</td>\n",
       "      <td>84.5(1.2)</td>\n",
       "      <td>80.4(2.9)</td>\n",
       "      <td>33.9(4.7)</td>\n",
       "      <td>30.3(0.0)</td>\n",
       "      <td>68.5(6.7)</td>\n",
       "      <td>72.3(2.6)</td>\n",
       "      <td>65.9(9.4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beef</td>\n",
       "      <td>72.0(2.8)</td>\n",
       "      <td>69.7(4.0)</td>\n",
       "      <td>75.3(4.2)</td>\n",
       "      <td>64.3(5.0)</td>\n",
       "      <td>20.0(0.0)</td>\n",
       "      <td>20.0(0.0)</td>\n",
       "      <td>56.3(7.8)</td>\n",
       "      <td>76.3(1.1)</td>\n",
       "      <td>53.7(14.9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BeetleFly</td>\n",
       "      <td>87.0(2.6)</td>\n",
       "      <td>86.0(9.7)</td>\n",
       "      <td>85.0(2.4)</td>\n",
       "      <td>74.5(7.6)</td>\n",
       "      <td>50.0(0.0)</td>\n",
       "      <td>50.0(0.0)</td>\n",
       "      <td>58.0(9.2)</td>\n",
       "      <td>89.0(3.2)</td>\n",
       "      <td>73.0(7.9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>uWaveGestureLibrary_Z</td>\n",
       "      <td>69.7(0.2)</td>\n",
       "      <td>72.6(0.5)</td>\n",
       "      <td>75.0(0.4)</td>\n",
       "      <td>71.1(0.5)</td>\n",
       "      <td>18.0(18.4)</td>\n",
       "      <td>12.1(0.0)</td>\n",
       "      <td>65.0(1.8)</td>\n",
       "      <td>64.2(0.9)</td>\n",
       "      <td>56.5(2.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>wafer</td>\n",
       "      <td>99.6(0.0)</td>\n",
       "      <td>99.7(0.0)</td>\n",
       "      <td>99.9(0.1)</td>\n",
       "      <td>99.6(0.0)</td>\n",
       "      <td>91.3(4.4)</td>\n",
       "      <td>89.2(0.0)</td>\n",
       "      <td>99.2(0.3)</td>\n",
       "      <td>96.1(0.1)</td>\n",
       "      <td>91.4(0.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>yoga</td>\n",
       "      <td>85.5(0.4)</td>\n",
       "      <td>83.9(0.7)</td>\n",
       "      <td>87.0(0.9)</td>\n",
       "      <td>82.0(0.6)</td>\n",
       "      <td>53.6(0.0)</td>\n",
       "      <td>53.6(0.0)</td>\n",
       "      <td>76.2(3.9)</td>\n",
       "      <td>78.1(0.7)</td>\n",
       "      <td>60.7(1.9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Average_Rank</td>\n",
       "      <td>4.611765</td>\n",
       "      <td>2.682353</td>\n",
       "      <td>1.994118</td>\n",
       "      <td>3.682353</td>\n",
       "      <td>8.017647</td>\n",
       "      <td>8.417647</td>\n",
       "      <td>5.376471</td>\n",
       "      <td>4.970588</td>\n",
       "      <td>5.247059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Wins</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Unnamed: 0        MLP        FCN     ResNet    Encoder  \\\n",
       "0                 50words  68.4(7.1)  62.7(6.1)  74.0(1.5)  72.3(1.0)   \n",
       "1                   Adiac  39.7(1.9)  84.4(0.7)  82.9(0.6)  48.4(2.5)   \n",
       "2               ArrowHead  77.8(1.2)  84.3(1.5)  84.5(1.2)  80.4(2.9)   \n",
       "3                    Beef  72.0(2.8)  69.7(4.0)  75.3(4.2)  64.3(5.0)   \n",
       "4               BeetleFly  87.0(2.6)  86.0(9.7)  85.0(2.4)  74.5(7.6)   \n",
       "..                    ...        ...        ...        ...        ...   \n",
       "82  uWaveGestureLibrary_Z  69.7(0.2)  72.6(0.5)  75.0(0.4)  71.1(0.5)   \n",
       "83                  wafer  99.6(0.0)  99.7(0.0)  99.9(0.1)  99.6(0.0)   \n",
       "84                   yoga  85.5(0.4)  83.9(0.7)  87.0(0.9)  82.0(0.6)   \n",
       "85           Average_Rank   4.611765   2.682353   1.994118   3.682353   \n",
       "86                   Wins          4         18         41         10   \n",
       "\n",
       "          MCNN    t-LeNet     MCDCNN   Time-CNN      TWIESN  \n",
       "0   22.0(24.3)  12.5(0.0)  58.9(5.3)  62.1(1.0)   49.6(2.6)  \n",
       "1     2.2(0.6)   2.0(0.0)  61.0(8.7)  37.9(2.0)   41.6(4.5)  \n",
       "2    33.9(4.7)  30.3(0.0)  68.5(6.7)  72.3(2.6)   65.9(9.4)  \n",
       "3    20.0(0.0)  20.0(0.0)  56.3(7.8)  76.3(1.1)  53.7(14.9)  \n",
       "4    50.0(0.0)  50.0(0.0)  58.0(9.2)  89.0(3.2)   73.0(7.9)  \n",
       "..         ...        ...        ...        ...         ...  \n",
       "82  18.0(18.4)  12.1(0.0)  65.0(1.8)  64.2(0.9)   56.5(2.0)  \n",
       "83   91.3(4.4)  89.2(0.0)  99.2(0.3)  96.1(0.1)   91.4(0.5)  \n",
       "84   53.6(0.0)  53.6(0.0)  76.2(3.9)  78.1(0.7)   60.7(1.9)  \n",
       "85    8.017647   8.417647   5.376471   4.970588    5.247059  \n",
       "86           0          0          3          4           1  \n",
       "\n",
       "[87 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_uea=pd.read_csv(\"results-uea-avg-std.csv\")\n",
    "results_uea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Train loss</th>\n",
       "      <th>Train accuracy</th>\n",
       "      <th>Test loss</th>\n",
       "      <th>Test accuracy</th>\n",
       "      <th>MLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ArrowHead</td>\n",
       "      <td>1.369213e-05</td>\n",
       "      <td>100.00</td>\n",
       "      <td>5.680031</td>\n",
       "      <td>73.71</td>\n",
       "      <td>77.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wine</td>\n",
       "      <td>6.917889e-01</td>\n",
       "      <td>52.63</td>\n",
       "      <td>0.694254</td>\n",
       "      <td>50.00</td>\n",
       "      <td>56.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OliveOil</td>\n",
       "      <td>1.282214e+00</td>\n",
       "      <td>43.33</td>\n",
       "      <td>1.298481</td>\n",
       "      <td>40.00</td>\n",
       "      <td>66.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Car</td>\n",
       "      <td>1.869125e-01</td>\n",
       "      <td>93.33</td>\n",
       "      <td>1.410494</td>\n",
       "      <td>63.33</td>\n",
       "      <td>76.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BeetleFly</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>4.377611</td>\n",
       "      <td>80.00</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Yoga</td>\n",
       "      <td>6.893885e-01</td>\n",
       "      <td>54.33</td>\n",
       "      <td>0.690694</td>\n",
       "      <td>53.57</td>\n",
       "      <td>85.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>InlineSkate</td>\n",
       "      <td>1.742696e+00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>3.922623</td>\n",
       "      <td>20.36</td>\n",
       "      <td>33.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FaceAll</td>\n",
       "      <td>2.610312e+00</td>\n",
       "      <td>8.21</td>\n",
       "      <td>2.632383</td>\n",
       "      <td>4.02</td>\n",
       "      <td>79.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ham</td>\n",
       "      <td>1.421762e-08</td>\n",
       "      <td>100.00</td>\n",
       "      <td>7.896139</td>\n",
       "      <td>64.76</td>\n",
       "      <td>69.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MoteStrain</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>3.974996</td>\n",
       "      <td>81.23</td>\n",
       "      <td>85.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ProximalPhalanxTW</td>\n",
       "      <td>2.818533e-01</td>\n",
       "      <td>89.25</td>\n",
       "      <td>0.648721</td>\n",
       "      <td>79.51</td>\n",
       "      <td>76.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>WordSynonyms</td>\n",
       "      <td>2.329328e+00</td>\n",
       "      <td>28.09</td>\n",
       "      <td>4.058908</td>\n",
       "      <td>23.04</td>\n",
       "      <td>59.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Lightning7</td>\n",
       "      <td>1.362392e-08</td>\n",
       "      <td>100.00</td>\n",
       "      <td>5.759298</td>\n",
       "      <td>61.64</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GunPointOldVersusYoung</td>\n",
       "      <td>1.060608e-07</td>\n",
       "      <td>100.00</td>\n",
       "      <td>3.354231</td>\n",
       "      <td>93.97</td>\n",
       "      <td>92.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Earthquakes</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>94.589607</td>\n",
       "      <td>73.38</td>\n",
       "      <td>71.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Dataset    Train loss  Train accuracy  Test loss  \\\n",
       "0                ArrowHead  1.369213e-05          100.00   5.680031   \n",
       "1                     Wine  6.917889e-01           52.63   0.694254   \n",
       "2                 OliveOil  1.282214e+00           43.33   1.298481   \n",
       "3                      Car  1.869125e-01           93.33   1.410494   \n",
       "4                BeetleFly  0.000000e+00          100.00   4.377611   \n",
       "5                     Yoga  6.893885e-01           54.33   0.690694   \n",
       "6              InlineSkate  1.742696e+00           26.00   3.922623   \n",
       "7                  FaceAll  2.610312e+00            8.21   2.632383   \n",
       "8                      Ham  1.421762e-08          100.00   7.896139   \n",
       "9               MoteStrain  0.000000e+00          100.00   3.974996   \n",
       "10       ProximalPhalanxTW  2.818533e-01           89.25   0.648721   \n",
       "11            WordSynonyms  2.329328e+00           28.09   4.058908   \n",
       "12              Lightning7  1.362392e-08          100.00   5.759298   \n",
       "13  GunPointOldVersusYoung  1.060608e-07          100.00   3.354231   \n",
       "14             Earthquakes  0.000000e+00          100.00  94.589607   \n",
       "\n",
       "    Test accuracy   MLP  \n",
       "0           73.71  77.8  \n",
       "1           50.00  56.5  \n",
       "2           40.00  66.7  \n",
       "3           63.33  76.7  \n",
       "4           80.00  87.0  \n",
       "5           53.57  85.5  \n",
       "6           20.36  33.7  \n",
       "7            4.02  79.3  \n",
       "8           64.76  69.1  \n",
       "9           81.23  85.8  \n",
       "10          79.51  76.7  \n",
       "11          23.04  59.8  \n",
       "12          61.64  63.0  \n",
       "13          93.97  92.7  \n",
       "14          73.38  71.7  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"results-uea-avg-std.csv\")\n",
    "\n",
    "# remove std\n",
    "def remove_parenthesis(value):\n",
    "    return float(value.split(\"(\")[0])\n",
    "\n",
    "def convert_to_percent(value):\n",
    "    return float(\"%.2f\" % float(value*100))\n",
    "\n",
    "df.iloc[:, 1:] = df.iloc[:, 1:].map(remove_parenthesis)\n",
    "results[\"Train accuracy\"]=results[\"Train accuracy\"].apply(convert_to_percent)\n",
    "results[\"Test accuracy\"]=results[\"Test accuracy\"].apply(convert_to_percent)\n",
    "\n",
    "df['Unnamed: 0'] = df['Unnamed: 0'].str.lower()\n",
    "dataset_names = pd.Series(UNIVARIATE_DATASET_NAMES_2018, name=\"Unnamed: 0\").str.lower()\n",
    "df_copy = df.merge(dataset_names, on='Unnamed: 0', how='right')\n",
    "df_copy.dropna(axis=0, inplace=True)\n",
    "\n",
    "results['Unnamed: 0'] = results['Dataset'].str.lower()\n",
    "\n",
    "# merge and remove unused columns\n",
    "result = results.merge(df_copy[[\"Unnamed: 0\",\"MLP\"]],on=\"Unnamed: 0\",how=\"right\").drop(\"Unnamed: 0\",axis=1)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_1v1_perf(result,\"MLP\",\"Test accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16c1a6cef089e7df03eb3ef6b302c9876f8716d8e0fa74aeb62504d533a43d66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
