{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-13 14:32:20.780094: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-13 14:32:21.554142: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-13 14:32:22.600976: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-13 14:32:22.632232: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-13 14:32:22.632384: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-13 14:32:22.633616: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-13 14:32:22.633806: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-13 14:32:22.633915: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-13 14:32:23.177632: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-13 14:32:23.177785: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-13 14:32:23.177902: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-13 14:32:23.177993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 923 MB memory:  -> device: 0, name: Quadro P400, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1081, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/losses.py\", line 2122, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/backend.py\", line 5560, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 36) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m df \u001b[38;5;241m=\u001b[39m read_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArrowHead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m MultiLayerPerceptron()\n\u001b[0;32m---> 12\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/MLP_MultiLayerPerceptron/models/MLP.py:27\u001b[0m, in \u001b[0;36mMultiLayerPerceptron.fit\u001b[0;34m(self, dataset, labels, batch_size, hidden_units)\u001b[0m\n\u001b[1;32m     24\u001b[0m model\u001b[39m.\u001b[39madd(Activation(\u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m     26\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 27\u001b[0m model\u001b[39m.\u001b[39;49mfit(dataset, labels, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49mbatch_size)\n\u001b[1;32m     29\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filem84keltk.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1081, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/losses.py\", line 2122, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/backend.py\", line 5560, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 36) are incompatible\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from utils.helper import *\n",
    "from models.MLP import MultiLayerPerceptron\n",
    "\n",
    "df = read_dataset(\"ArrowHead\")\n",
    "\n",
    "model = MultiLayerPerceptron()\n",
    "\n",
    "history = model.fit(df[0],df[1],20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 3)\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-13 17:21:44.915623: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:425] Loaded runtime CuDNN library: 8.4.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2024-02-13 17:21:44.916788: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n",
      "2024-02-13 17:21:44.923059: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:425] Loaded runtime CuDNN library: 8.4.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2024-02-13 17:21:44.923907: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n",
      "2024-02-13 17:21:44.929756: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:425] Loaded runtime CuDNN library: 8.4.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2024-02-13 17:21:44.930692: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n",
      "2024-02-13 17:21:44.937357: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:425] Loaded runtime CuDNN library: 8.4.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2024-02-13 17:21:44.938286: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n",
      "2024-02-13 17:21:44.944206: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:425] Loaded runtime CuDNN library: 8.4.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2024-02-13 17:21:44.945048: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n",
      "2024-02-13 17:21:44.951401: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:425] Loaded runtime CuDNN library: 8.4.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2024-02-13 17:21:44.952345: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n",
      "2024-02-13 17:21:44.958433: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:425] Loaded runtime CuDNN library: 8.4.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2024-02-13 17:21:44.959305: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n",
      "2024-02-13 17:21:44.965074: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:425] Loaded runtime CuDNN library: 8.4.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2024-02-13 17:21:44.966252: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Graph execution error:\n\nDetected at node 'RMSprop/StatefulPartitionedCall_6' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n      app.start()\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 542, in dispatch_queue\n      await self.process_one()\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 531, in process_one\n      await dispatch(*args)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 775, in execute_request\n      reply_content = await reply_content\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n      res = shell.run_cell(\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_521768/2205995068.py\", line 26, in <module>\n      history = model.fit(df[0], y_train, batch_size=32, epochs=10, validation_split=0.2)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1084, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/optimizers/optimizer.py\", line 544, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/optimizers/optimizer.py\", line 1230, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/optimizers/optimizer.py\", line 652, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/optimizers/optimizer.py\", line 1260, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/optimizers/optimizer.py\", line 1352, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/optimizers/optimizer.py\", line 1347, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'RMSprop/StatefulPartitionedCall_6'\nDNN library initialization failed. Look at the errors above for more details.\n\t [[{{node RMSprop/StatefulPartitionedCall_6}}]] [Op:__inference_train_function_9640]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39mCategoricalCrossentropy())\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m     29\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(df[\u001b[38;5;241m2\u001b[39m], df[\u001b[38;5;241m3\u001b[39m])\n",
      "File \u001b[0;32m~/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Graph execution error:\n\nDetected at node 'RMSprop/StatefulPartitionedCall_6' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n      app.start()\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 542, in dispatch_queue\n      await self.process_one()\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 531, in process_one\n      await dispatch(*args)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 775, in execute_request\n      reply_content = await reply_content\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n      res = shell.run_cell(\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_521768/2205995068.py\", line 26, in <module>\n      history = model.fit(df[0], y_train, batch_size=32, epochs=10, validation_split=0.2)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1084, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/optimizers/optimizer.py\", line 544, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/optimizers/optimizer.py\", line 1230, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/optimizers/optimizer.py\", line 652, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/optimizers/optimizer.py\", line 1260, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/optimizers/optimizer.py\", line 1352, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"/home/elnur/Desktop/MLP_MultiLayerPerceptron/env/lib/python3.8/site-packages/keras/src/optimizers/optimizer.py\", line 1347, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'RMSprop/StatefulPartitionedCall_6'\nDNN library initialization failed. Look at the errors above for more details.\n\t [[{{node RMSprop/StatefulPartitionedCall_6}}]] [Op:__inference_train_function_9640]"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "\n",
    "from utils.helper import *\n",
    "from models.MLP import MultiLayerPerceptron\n",
    "\n",
    "df = read_dataset(\"ArrowHead\")\n",
    "\n",
    "\n",
    "y_train=to_categorical(df[1])\n",
    "\n",
    "\n",
    "print(y_train.shape)\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model = MultiLayerPerceptron(input_size=df[0].shape[1], num_labels=y_train.shape[1])\n",
    "model.compile(loss=CategoricalCrossentropy())\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(df[0], y_train, batch_size=32, epochs=10, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(df[2], df[3])\n",
    "print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-14 15:02:09.172172: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-14 15:02:09.172200: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-14 15:02:09.173298: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-14 15:02:09.179013: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-14 15:02:09.906774: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-02-14 15:02:10.569329: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-14 15:02:10.603943: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-14 15:02:10.604117: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-14 15:02:10.661246: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-14 15:02:10.661405: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-14 15:02:10.661526: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-14 15:02:10.661656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 1739 MB memory:  -> device: 0, name: Quadro P400, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1280541137156407029\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1823539200\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 5973102883161820459\n",
      "physical_device_desc: \"device: 0, name: Quadro P400, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-14 15:02:11.021969: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-14 15:02:11.022200: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-14 15:02:11.022329: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-14 15:02:11.044284: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-14 15:02:11.044459: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-14 15:02:11.044569: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-14 15:02:11.044708: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-14 15:02:11.044818: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-14 15:02:11.044902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1739 MB memory:  -> device: 0, name: Quadro P400, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Epoch 1/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-14 15:02:11.861973: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fc2488b19d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-02-14 15:02:11.861998: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro P400, Compute Capability 6.1\n",
      "2024-02-14 15:02:11.867383: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-02-14 15:02:11.881387: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1707919331.942483   69983 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 1.1637 - accuracy: 0.3571 - val_loss: 1.2060 - val_accuracy: 0.5000\n",
      "Epoch 2/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0386 - accuracy: 0.5000 - val_loss: 0.8306 - val_accuracy: 0.6250\n",
      "Epoch 3/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.7068 - accuracy: 0.6071 - val_loss: 0.8775 - val_accuracy: 0.5000\n",
      "Epoch 4/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6951 - accuracy: 0.6071 - val_loss: 0.6531 - val_accuracy: 0.8750\n",
      "Epoch 5/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5118 - accuracy: 0.8214 - val_loss: 0.6567 - val_accuracy: 0.6250\n",
      "Epoch 6/10000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4825 - accuracy: 0.8214 - val_loss: 0.6611 - val_accuracy: 0.5000\n",
      "Epoch 7/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4631 - accuracy: 0.8214 - val_loss: 0.5800 - val_accuracy: 0.7500\n",
      "Epoch 8/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4164 - accuracy: 0.8929 - val_loss: 0.5381 - val_accuracy: 0.8750\n",
      "Epoch 9/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3743 - accuracy: 0.8929 - val_loss: 0.6221 - val_accuracy: 0.6250\n",
      "Epoch 10/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3726 - accuracy: 0.8214 - val_loss: 0.5317 - val_accuracy: 0.8750\n",
      "Epoch 11/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3242 - accuracy: 0.8929 - val_loss: 0.4843 - val_accuracy: 0.7500\n",
      "Epoch 12/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3061 - accuracy: 0.8929 - val_loss: 0.5130 - val_accuracy: 0.6250\n",
      "Epoch 13/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2911 - accuracy: 0.8929 - val_loss: 0.4693 - val_accuracy: 0.8750\n",
      "Epoch 14/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2613 - accuracy: 0.8571 - val_loss: 0.4394 - val_accuracy: 1.0000\n",
      "Epoch 15/10000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2486 - accuracy: 0.8929 - val_loss: 0.5552 - val_accuracy: 0.7500\n",
      "Epoch 16/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2318 - accuracy: 0.8929 - val_loss: 0.4619 - val_accuracy: 0.7500\n",
      "Epoch 17/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1978 - accuracy: 0.9286 - val_loss: 0.3763 - val_accuracy: 0.8750\n",
      "Epoch 18/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1901 - accuracy: 0.9286 - val_loss: 0.4136 - val_accuracy: 0.7500\n",
      "Epoch 19/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1667 - accuracy: 0.9286 - val_loss: 0.4064 - val_accuracy: 0.7500\n",
      "Epoch 20/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1387 - accuracy: 0.9643 - val_loss: 0.4007 - val_accuracy: 0.8750\n",
      "Epoch 21/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1335 - accuracy: 0.9643 - val_loss: 0.5302 - val_accuracy: 0.7500\n",
      "Epoch 22/10000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1096 - accuracy: 1.0000 - val_loss: 0.4578 - val_accuracy: 0.8750\n",
      "Epoch 23/10000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0903 - accuracy: 1.0000 - val_loss: 0.3135 - val_accuracy: 0.8750\n",
      "Epoch 24/10000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0831 - accuracy: 1.0000 - val_loss: 0.3632 - val_accuracy: 0.8750\n",
      "Epoch 25/10000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0626 - accuracy: 1.0000 - val_loss: 0.4914 - val_accuracy: 0.8750\n",
      "Epoch 26/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0557 - accuracy: 1.0000 - val_loss: 0.4665 - val_accuracy: 0.8750\n",
      "Epoch 27/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0452 - accuracy: 1.0000 - val_loss: 0.4103 - val_accuracy: 0.8750\n",
      "Epoch 28/10000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0391 - accuracy: 1.0000 - val_loss: 0.4035 - val_accuracy: 0.8750\n",
      "Epoch 29/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.4104 - val_accuracy: 0.8750\n",
      "Epoch 30/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.3766 - val_accuracy: 0.8750\n",
      "Epoch 31/10000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.3907 - val_accuracy: 0.8750\n",
      "Epoch 32/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.4644 - val_accuracy: 0.8750\n",
      "Epoch 33/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.5415 - val_accuracy: 0.8750\n",
      "Epoch 34/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.5368 - val_accuracy: 0.8750\n",
      "Epoch 35/10000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.4654 - val_accuracy: 0.8750\n",
      "Epoch 36/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.4151 - val_accuracy: 0.8750\n",
      "Epoch 37/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.4212 - val_accuracy: 0.8750\n",
      "Epoch 38/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.4779 - val_accuracy: 0.8750\n",
      "Epoch 39/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.5516 - val_accuracy: 0.8750\n",
      "Epoch 40/10000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.6004 - val_accuracy: 0.8750\n",
      "Epoch 41/10000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.6146 - val_accuracy: 0.8750\n",
      "Epoch 42/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.6161 - val_accuracy: 0.8750\n",
      "Epoch 43/10000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.6221 - val_accuracy: 0.8750\n",
      "Epoch 44/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6398 - val_accuracy: 0.8750\n",
      "Epoch 45/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6658 - val_accuracy: 0.8750\n",
      "Epoch 46/10000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6901 - val_accuracy: 0.8750\n",
      "Epoch 47/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.7007 - val_accuracy: 0.8750\n",
      "Epoch 48/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6943 - val_accuracy: 0.8750\n",
      "Epoch 49/10000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6741 - val_accuracy: 0.8750\n",
      "Epoch 50/10000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6502 - val_accuracy: 0.8750\n",
      "Epoch 51/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6322 - val_accuracy: 0.8750\n",
      "Epoch 52/10000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6267 - val_accuracy: 0.8750\n",
      "Epoch 53/10000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6362 - val_accuracy: 0.8750\n",
      "Epoch 54/10000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6578 - val_accuracy: 0.8750\n",
      "Epoch 55/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6865 - val_accuracy: 0.8750\n",
      "Epoch 56/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.7173 - val_accuracy: 0.8750\n",
      "Epoch 57/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 9.4946e-04 - accuracy: 1.0000 - val_loss: 0.7438 - val_accuracy: 0.8750\n",
      "Epoch 58/10000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 9.0712e-04 - accuracy: 1.0000 - val_loss: 0.7623 - val_accuracy: 0.8750\n",
      "Epoch 59/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 8.6584e-04 - accuracy: 1.0000 - val_loss: 0.7710 - val_accuracy: 0.8750\n",
      "Epoch 60/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 8.1804e-04 - accuracy: 1.0000 - val_loss: 0.7713 - val_accuracy: 0.8750\n",
      "Epoch 61/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.7002e-04 - accuracy: 1.0000 - val_loss: 0.7663 - val_accuracy: 0.8750\n",
      "Epoch 62/10000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.3033e-04 - accuracy: 1.0000 - val_loss: 0.7596 - val_accuracy: 0.8750\n",
      "Epoch 63/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.0061e-04 - accuracy: 1.0000 - val_loss: 0.7537 - val_accuracy: 0.8750\n",
      "Epoch 64/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6.7602e-04 - accuracy: 1.0000 - val_loss: 0.7505 - val_accuracy: 0.8750\n",
      "Epoch 65/10000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 6.5074e-04 - accuracy: 1.0000 - val_loss: 0.7506 - val_accuracy: 0.8750\n",
      "Epoch 66/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6.2302e-04 - accuracy: 1.0000 - val_loss: 0.7536 - val_accuracy: 0.8750\n",
      "Epoch 67/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.9491e-04 - accuracy: 1.0000 - val_loss: 0.7582 - val_accuracy: 0.8750\n",
      "Epoch 68/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.7005e-04 - accuracy: 1.0000 - val_loss: 0.7631 - val_accuracy: 0.8750\n",
      "Epoch 69/10000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.4990e-04 - accuracy: 1.0000 - val_loss: 0.7666 - val_accuracy: 0.8750\n",
      "Epoch 70/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.3411e-04 - accuracy: 1.0000 - val_loss: 0.7675 - val_accuracy: 0.8750\n",
      "Epoch 71/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 5.2001e-04 - accuracy: 1.0000 - val_loss: 0.7656 - val_accuracy: 0.8750\n",
      "Epoch 72/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 5.0564e-04 - accuracy: 1.0000 - val_loss: 0.7613 - val_accuracy: 0.8750\n",
      "Epoch 73/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.9076e-04 - accuracy: 1.0000 - val_loss: 0.7557 - val_accuracy: 0.8750\n",
      "Epoch 74/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.7623e-04 - accuracy: 1.0000 - val_loss: 0.7499 - val_accuracy: 0.8750\n",
      "Epoch 75/10000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.6329e-04 - accuracy: 1.0000 - val_loss: 0.7456 - val_accuracy: 0.8750\n",
      "Epoch 76/10000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.5199e-04 - accuracy: 1.0000 - val_loss: 0.7435 - val_accuracy: 0.8750\n",
      "Epoch 77/10000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.4194e-04 - accuracy: 1.0000 - val_loss: 0.7442 - val_accuracy: 0.8750\n",
      "Epoch 78/10000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.3209e-04 - accuracy: 1.0000 - val_loss: 0.7475 - val_accuracy: 0.8750\n",
      "Epoch 79/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.2199e-04 - accuracy: 1.0000 - val_loss: 0.7528 - val_accuracy: 0.8750\n",
      "Epoch 80/10000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.1208e-04 - accuracy: 1.0000 - val_loss: 0.7596 - val_accuracy: 0.8750\n",
      "Epoch 81/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.0268e-04 - accuracy: 1.0000 - val_loss: 0.7668 - val_accuracy: 0.8750\n",
      "Epoch 82/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.9418e-04 - accuracy: 1.0000 - val_loss: 0.7735 - val_accuracy: 0.8750\n",
      "Epoch 83/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.8653e-04 - accuracy: 1.0000 - val_loss: 0.7790 - val_accuracy: 0.8750\n",
      "Epoch 84/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.7947e-04 - accuracy: 1.0000 - val_loss: 0.7826 - val_accuracy: 0.8750\n",
      "Epoch 85/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.7256e-04 - accuracy: 1.0000 - val_loss: 0.7844 - val_accuracy: 0.8750\n",
      "Epoch 86/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.6565e-04 - accuracy: 1.0000 - val_loss: 0.7844 - val_accuracy: 0.8750\n",
      "Epoch 87/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.5882e-04 - accuracy: 1.0000 - val_loss: 0.7833 - val_accuracy: 0.8750\n",
      "Epoch 88/10000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.5216e-04 - accuracy: 1.0000 - val_loss: 0.7813 - val_accuracy: 0.8750\n",
      "Epoch 89/10000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.4596e-04 - accuracy: 1.0000 - val_loss: 0.7789 - val_accuracy: 0.8750\n",
      "Epoch 90/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.4030e-04 - accuracy: 1.0000 - val_loss: 0.7770 - val_accuracy: 0.8750\n",
      "Epoch 91/10000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.3484e-04 - accuracy: 1.0000 - val_loss: 0.7758 - val_accuracy: 0.8750\n",
      "Epoch 92/10000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.2950e-04 - accuracy: 1.0000 - val_loss: 0.7755 - val_accuracy: 0.8750\n",
      "Epoch 93/10000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.2419e-04 - accuracy: 1.0000 - val_loss: 0.7760 - val_accuracy: 0.8750\n",
      "Epoch 94/10000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.1892e-04 - accuracy: 1.0000 - val_loss: 0.7771 - val_accuracy: 0.8750\n",
      "Epoch 95/10000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.1378e-04 - accuracy: 1.0000 - val_loss: 0.7788 - val_accuracy: 0.8750\n",
      "Epoch 96/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.0879e-04 - accuracy: 1.0000 - val_loss: 0.7808 - val_accuracy: 0.8750\n",
      "Epoch 97/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.0413e-04 - accuracy: 1.0000 - val_loss: 0.7825 - val_accuracy: 0.8750\n",
      "Epoch 98/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.9972e-04 - accuracy: 1.0000 - val_loss: 0.7837 - val_accuracy: 0.8750\n",
      "Epoch 99/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.9547e-04 - accuracy: 1.0000 - val_loss: 0.7844 - val_accuracy: 0.8750\n",
      "Epoch 100/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.9147e-04 - accuracy: 1.0000 - val_loss: 0.7848 - val_accuracy: 0.8750\n",
      "Epoch 101/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.8755e-04 - accuracy: 1.0000 - val_loss: 0.7848 - val_accuracy: 0.8750\n",
      "Epoch 102/10000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.8368e-04 - accuracy: 1.0000 - val_loss: 0.7847 - val_accuracy: 0.8750\n",
      "Epoch 103/10000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.7985e-04 - accuracy: 1.0000 - val_loss: 0.7845 - val_accuracy: 0.8750\n",
      "Epoch 104/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.7616e-04 - accuracy: 1.0000 - val_loss: 0.7844 - val_accuracy: 0.8750\n",
      "Epoch 105/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.7265e-04 - accuracy: 1.0000 - val_loss: 0.7847 - val_accuracy: 0.8750\n",
      "Epoch 106/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.6926e-04 - accuracy: 1.0000 - val_loss: 0.7856 - val_accuracy: 0.8750\n",
      "Epoch 107/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.6593e-04 - accuracy: 1.0000 - val_loss: 0.7871 - val_accuracy: 0.8750\n",
      "Epoch 108/10000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.6264e-04 - accuracy: 1.0000 - val_loss: 0.7890 - val_accuracy: 0.8750\n",
      "Epoch 109/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.5946e-04 - accuracy: 1.0000 - val_loss: 0.7912 - val_accuracy: 0.8750\n",
      "Epoch 110/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.5633e-04 - accuracy: 1.0000 - val_loss: 0.7938 - val_accuracy: 0.8750\n",
      "Epoch 111/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.5329e-04 - accuracy: 1.0000 - val_loss: 0.7961 - val_accuracy: 0.8750\n",
      "Epoch 112/10000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.5029e-04 - accuracy: 1.0000 - val_loss: 0.7980 - val_accuracy: 0.8750\n",
      "Epoch 113/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.4739e-04 - accuracy: 1.0000 - val_loss: 0.7995 - val_accuracy: 0.8750\n",
      "Epoch 114/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.4454e-04 - accuracy: 1.0000 - val_loss: 0.8004 - val_accuracy: 0.8750\n",
      "Epoch 115/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.4176e-04 - accuracy: 1.0000 - val_loss: 0.8009 - val_accuracy: 0.8750\n",
      "Epoch 116/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.3899e-04 - accuracy: 1.0000 - val_loss: 0.8008 - val_accuracy: 0.8750\n",
      "Epoch 117/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.3624e-04 - accuracy: 1.0000 - val_loss: 0.8005 - val_accuracy: 0.8750\n",
      "Epoch 118/10000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.3360e-04 - accuracy: 1.0000 - val_loss: 0.8003 - val_accuracy: 0.8750\n",
      "Epoch 119/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.3099e-04 - accuracy: 1.0000 - val_loss: 0.8004 - val_accuracy: 0.8750\n",
      "Epoch 120/10000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.2845e-04 - accuracy: 1.0000 - val_loss: 0.8007 - val_accuracy: 0.8750\n",
      "Epoch 121/10000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.2591e-04 - accuracy: 1.0000 - val_loss: 0.8012 - val_accuracy: 0.8750\n",
      "Epoch 122/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.2346e-04 - accuracy: 1.0000 - val_loss: 0.8020 - val_accuracy: 0.8750\n",
      "Epoch 123/10000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.2101e-04 - accuracy: 1.0000 - val_loss: 0.8030 - val_accuracy: 0.8750\n",
      "Epoch 124/10000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.1865e-04 - accuracy: 1.0000 - val_loss: 0.8037 - val_accuracy: 0.8750\n",
      "Epoch 125/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.1635e-04 - accuracy: 1.0000 - val_loss: 0.8042 - val_accuracy: 0.8750\n",
      "Epoch 126/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.1401e-04 - accuracy: 1.0000 - val_loss: 0.8046 - val_accuracy: 0.8750\n",
      "Epoch 127/10000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.1175e-04 - accuracy: 1.0000 - val_loss: 0.8047 - val_accuracy: 0.8750\n",
      "Epoch 128/10000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.0949e-04 - accuracy: 1.0000 - val_loss: 0.8048 - val_accuracy: 0.8750\n",
      "Epoch 129/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.0728e-04 - accuracy: 1.0000 - val_loss: 0.8048 - val_accuracy: 0.8750\n",
      "Epoch 130/10000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.0514e-04 - accuracy: 1.0000 - val_loss: 0.8051 - val_accuracy: 0.8750\n",
      "Epoch 131/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.0300e-04 - accuracy: 1.0000 - val_loss: 0.8056 - val_accuracy: 0.8750\n",
      "Epoch 132/10000\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.0090e-04 - accuracy: 1.0000GPU memory has been successfully cleared."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "from utils.helper import *\n",
    "from models.MLP import MultiLayerPerceptron\n",
    "import os\n",
    "import sys\n",
    "\n",
    "def restart_kernel():\n",
    "    os.execl(sys.executable, sys.executable, *sys.argv)\n",
    "\n",
    "def clear_gpu_memory():\n",
    "    physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if physical_devices:\n",
    "        for device in physical_devices:\n",
    "            tf.config.experimental.set_memory_growth(device, True)\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "# Call clear_gpu_memory function before executing new operations\n",
    "clear_gpu_memory()\n",
    "\n",
    "def reset_gpu():\n",
    "    # Clear GPU memory\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            tf.keras.backend.clear_session()  # Clear TensorFlow session\n",
    "            print(\"GPU memory has been successfully cleared.\")\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "    else:\n",
    "        print(\"No GPU available. Nothing to clear.\")\n",
    "    \n",
    "    # Reset cuDNN, cuFFT, and cuBLAS factories\n",
    "    try:\n",
    "        tf.keras.backend.clear_session()  # Clear TensorFlow session again\n",
    "        print(\"cuDNN, cuFFT, and cuBLAS factories have been reset.\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "\n",
    "# Load data\n",
    "df = read_dataset(\"ArrowHead\")\n",
    "\n",
    "\n",
    "y_train=to_categorical(df[1])\n",
    "\n",
    "print(tf.config.list_physical_devices())\n",
    "\n",
    "\n",
    "try:\n",
    "    with tf.device(\"/device:GPU:0\"):\n",
    "        # Compile the model\n",
    "        model = MultiLayerPerceptron(input_size=df[0].shape[1], num_labels=y_train.shape[1])\n",
    "        model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['accuracy'])\n",
    "        # Train the model\n",
    "        history = model.fit(df[0], y_train, batch_size=32, epochs=10000, validation_split=0.2)\n",
    "        # Evaluate the model\n",
    "        loss, accuracy = model.evaluate(df[2], to_categorical(df[3]))\n",
    "        print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')\n",
    "except:\n",
    "    reset_gpu()\n",
    "    restart_kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16c1a6cef089e7df03eb3ef6b302c9876f8716d8e0fa74aeb62504d533a43d66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
